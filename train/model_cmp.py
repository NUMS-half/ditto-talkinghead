import torch


def compare_pth(model1_path, model2_path):
    # åŠ è½½æƒé‡
    state_dict1 = torch.load(model1_path, map_location="cpu")
    state_dict2 = torch.load(model2_path, map_location="cpu")

    # å¦‚æœåŒ…å« state_dict åŒ…è£…ï¼Œæå–å‡ºæ¥
    if "state_dict" in state_dict1:
        state_dict1 = state_dict1["state_dict"]
    if "state_dict" in state_dict2:
        state_dict2 = state_dict2["state_dict"]

    keys1, keys2 = set(state_dict1.keys()), set(state_dict2.keys())

    # æ‰¾ä¸åŒçš„å‚æ•° key
    only_in_1 = keys1 - keys2
    only_in_2 = keys2 - keys1
    common_keys = keys1 & keys2

    print("ğŸ”¹ ä»…åœ¨æ¨¡å‹1ä¸­çš„å‚æ•°:", only_in_1)
    print("ğŸ”¹ ä»…åœ¨æ¨¡å‹2ä¸­çš„å‚æ•°:", only_in_2)

    # å¯¹å…¬å…±å‚æ•°é€ä¸€æ¯”è¾ƒ
    diff_params = []
    for key in common_keys:
        t1, t2 = state_dict1[key], state_dict2[key]
        if t1.shape != t2.shape:
            diff_params.append((key, f"Shape ä¸åŒ: {t1.shape} vs {t2.shape}"))
        else:
            if not torch.equal(t1, t2):  # ç²¾ç¡®æ¯”è¾ƒï¼Œä¸è®¾å®¹å·®
                max_diff = (t1 - t2).abs().max().item()
                diff_params.append((key, f"æ•°å€¼ä¸åŒ (æœ€å¤§å·®å¼‚: {max_diff:.6f})"))

    if diff_params:
        print("\nâš ï¸ å…¬å…±å‚æ•°ä¸­çš„å·®å¼‚:")
        for k, v in diff_params:
            print(f"  {k}: {v}")
    else:
        print("\nâœ… å…¬å…±å‚æ•°å®Œå…¨ä¸€è‡´ï¼ˆé€å…ƒç´ ç›¸ç­‰ï¼‰.")


if __name__ == "__main__":
    compare_pth(
        "../checkpoints/ditto_pytorch/models/lmdm_v0.4_hubert.pth",
        "archive_20250916/training_checkpoints_finetune/ditto_lmdm_epoch_100.pth"
    )
